df= read.csv('~/Documents/GitHub/18FMath564-pj/data/train_processed.csv')
tdf= read.csv('~/Documents/GitHub/18FMath564-pj/data/test_processed.csv')
#remove first two columns which are index
df=df[,-c(1,2)]
tdf=tdf[,-c(1,2)]
# scale data since scaled data are required in some models
tdf_scale = scale(tdf,center=FALSE)
numv = names(train_procdata[,sapply(train_procdata,is.numeric)]) # numeric
numv
numv = names(train_procdata[,sapply(tdf,is.numeric)]) # numeric
numv = names(tdf[,sapply(tdf,is.numeric)]) # numeric
numv
# scale data since scaled data are required in some models
tdf_scale = scale(tdf[,numv],center=FALSE)
tdf_scale = data.frame(tdf_scale,tdf[,-numv])
tdf[,numv]
tdf[,-numv]
tdf[,c(-numv)]
catv = names(tdf[,sapply(tdf,is.factor)]) # numeric
catv
logv = names(tdf[,sapply(tdf,is.logical)]) # binary
logv
tdf_scale = data.frame(tdf_scale,tdf[,catv],tdf[,logv])
set.seed(564)
lm = train(SalePrice~., data = tdfmethod='lm',trControl=controlParameter)
summary(lm)
set.seed(564)
lm = train(SalePrice~., data = tdf,method='lm',trControl=controlParameter)
summary(lm)
# perform cross-validtion on training data set
library(caret)
install.packages('caret')
# perform cross-validtion on training data set
library(caret)
controlParameter=trainControl(method = "cv",number = 10,savePredictions = TRUE)
set.seed(564)
lm = train(SalePrice~., data = tdf,method='lm',trControl=controlParameter)
summary(lm)
df= read.csv('~/Documents/GitHub/18FMath564-pj/data/train_processed.csv')
testdf= read.csv('~/Documents/GitHub/18FMath564-pj/data/test_processed.csv')
#remove first two columns which are index
df=df[,-c(1,2)]
testdf=testdf[,-c(1,2)]
set.seed(564)
lm = train(SalePrice~., data = df,method='lm',trControl=controlParameter)
summary(lm)
library(leap)
?caret::train()
set.seed(564)
lm_forward=train(SalePrice~.,data=df,method='leapForward',trControl=controlParameter)
# variable selection by AIC stepwise algorithm
library(leaps)
# tree regression via rpart package
# grow the tree
tr=rpart(df$SalePrice~.,data = df, method = 'anova')
set.seed(564)
lm_forward=train(SalePrice~.,data=df,method='leapForward',trControl=controlParameter)
set.seed(564)
lm_step=train(SalePrice~.,data=df,method='leapSeq',trControl=controlParameter)
warnings()
lm_stepAIC=train(SalePrice~.,data=df,method='glmStepAIC',trControl=controlParameter)
# Make Prediction
lm_pred = predict(lm,df)
# To calculate AdjR2
lm_adjR2 = adjR2_test(lm_pred,df$SalePrice)
# define Adjusted R square function
adjR2_test = function (pred,y.test){
r2=miscTools::rSquared(y.test,resid = y.test-pred)
n=nrow(x.test)
q=ncol(x.test)
adjr2=1-((1-r2^2)*(n-1)/(n-q))
}
# define rmlse
rmlse <- function(yhat, y) {
n <- length(yhat)
return(sqrt((1/n)*sum((log(yhat)-log(y))^2)))
}
# To calculate AdjR2
lm_adjR2 = adjR2_test(lm_pred,df$SalePrice)
# To calculate rmlse
lm_rmlse = rmlse(abs(lm_pred), df$SalePrice)
#When we include the intercept it give ceofficient for pop.density=NA
#using the modelform include intercept=FALSE does not change the pop.density=NA
#The only solution that works was to manually type out the equation including -1
#This resulted in pop.denisty !=NA.
modelForm
?rs2
?rsquare
??rsquare
summary(lm)
